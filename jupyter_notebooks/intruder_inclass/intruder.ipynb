{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from scipy.sparse import csc_matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# функция для записи прогнозов в файл\n",
    "def write_to_submission_file(predicted_labels, out_file,\n",
    "                             target='target', index_label=\"session_id\"):\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                index = np.arange(1, predicted_labels.shape[0] + 1),\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_auc_lr_valid(X, y, C=1.0, ratio=0.9):\n",
    "    # разделим выборку на обучающую и валидационную\n",
    "    idx = round(X.shape[0] * ratio)\n",
    "    # обучение классификатора\n",
    "    lr = LogisticRegression(C=C, n_jobs=-1).fit(X[:idx, :], y[:idx])\n",
    "    # прогноз для валидационной выборки\n",
    "    y_pred = lr.predict_proba(X[idx:, :])[:, 1]\n",
    "    # считаем качество\n",
    "    score = roc_auc_score(y[idx:], y_pred)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../../data/intruder/train_sessions.csv\")\n",
    "test_df = pd.read_csv(\"../../data/intruder/test_sessions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "times = ['time%s' % i for i in range(1, 11)] \n",
    "train_df[times] = train_df[times].apply(pd.to_datetime)\n",
    "test_df[times] = test_df[times].apply(pd.to_datetime)\n",
    "\n",
    "train_df = train_df.sort_values(by='time1')\n",
    "sorted_test_df = test_df.sort_values(by='time1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sites = ['site%s' % i for i in range(1, 11)]\n",
    "train_df[sites] = train_df[sites].fillna(0).astype(np.int32)\n",
    "test_df[sites] = test_df[sites].fillna(0).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>site1</th>\n",
       "      <th>time1</th>\n",
       "      <th>site2</th>\n",
       "      <th>time2</th>\n",
       "      <th>site3</th>\n",
       "      <th>time3</th>\n",
       "      <th>site4</th>\n",
       "      <th>time4</th>\n",
       "      <th>site5</th>\n",
       "      <th>...</th>\n",
       "      <th>time6</th>\n",
       "      <th>site7</th>\n",
       "      <th>time7</th>\n",
       "      <th>site8</th>\n",
       "      <th>time8</th>\n",
       "      <th>site9</th>\n",
       "      <th>time9</th>\n",
       "      <th>site10</th>\n",
       "      <th>time10</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12223</th>\n",
       "      <td>12224</td>\n",
       "      <td>50</td>\n",
       "      <td>2014-04-30 23:33:48</td>\n",
       "      <td>50</td>\n",
       "      <td>2014-04-30 23:33:49</td>\n",
       "      <td>48</td>\n",
       "      <td>2014-04-30 23:33:52</td>\n",
       "      <td>49</td>\n",
       "      <td>2014-04-30 23:33:52</td>\n",
       "      <td>48</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-04-30 23:33:53</td>\n",
       "      <td>52</td>\n",
       "      <td>2014-04-30 23:33:54</td>\n",
       "      <td>49</td>\n",
       "      <td>2014-04-30 23:33:54</td>\n",
       "      <td>303</td>\n",
       "      <td>2014-04-30 23:33:57</td>\n",
       "      <td>304</td>\n",
       "      <td>2014-04-30 23:34:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164437</th>\n",
       "      <td>164438</td>\n",
       "      <td>4207</td>\n",
       "      <td>2014-04-30 23:34:15</td>\n",
       "      <td>753</td>\n",
       "      <td>2014-04-30 23:34:16</td>\n",
       "      <td>753</td>\n",
       "      <td>2014-04-30 23:34:17</td>\n",
       "      <td>52</td>\n",
       "      <td>2014-04-30 23:34:18</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-04-30 23:35:16</td>\n",
       "      <td>3346</td>\n",
       "      <td>2014-04-30 23:35:29</td>\n",
       "      <td>3359</td>\n",
       "      <td>2014-04-30 23:36:12</td>\n",
       "      <td>3346</td>\n",
       "      <td>2014-04-30 23:36:42</td>\n",
       "      <td>38</td>\n",
       "      <td>2014-04-30 23:37:13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12220</th>\n",
       "      <td>12221</td>\n",
       "      <td>52</td>\n",
       "      <td>2014-04-30 23:38:08</td>\n",
       "      <td>3346</td>\n",
       "      <td>2014-04-30 23:38:10</td>\n",
       "      <td>784</td>\n",
       "      <td>2014-04-30 23:38:13</td>\n",
       "      <td>784</td>\n",
       "      <td>2014-04-30 23:38:18</td>\n",
       "      <td>3346</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-04-30 23:38:24</td>\n",
       "      <td>3324</td>\n",
       "      <td>2014-04-30 23:38:35</td>\n",
       "      <td>7330</td>\n",
       "      <td>2014-04-30 23:38:35</td>\n",
       "      <td>3594</td>\n",
       "      <td>2014-04-30 23:38:35</td>\n",
       "      <td>3329</td>\n",
       "      <td>2014-04-30 23:38:36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156967</th>\n",
       "      <td>156968</td>\n",
       "      <td>3328</td>\n",
       "      <td>2014-04-30 23:38:36</td>\n",
       "      <td>3324</td>\n",
       "      <td>2014-04-30 23:38:36</td>\n",
       "      <td>3599</td>\n",
       "      <td>2014-04-30 23:38:38</td>\n",
       "      <td>3413</td>\n",
       "      <td>2014-04-30 23:38:38</td>\n",
       "      <td>753</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-04-30 23:38:40</td>\n",
       "      <td>3599</td>\n",
       "      <td>2014-04-30 23:38:40</td>\n",
       "      <td>3359</td>\n",
       "      <td>2014-04-30 23:39:07</td>\n",
       "      <td>3359</td>\n",
       "      <td>2014-04-30 23:39:08</td>\n",
       "      <td>3346</td>\n",
       "      <td>2014-04-30 23:39:53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204761</th>\n",
       "      <td>204762</td>\n",
       "      <td>222</td>\n",
       "      <td>2014-04-30 23:39:53</td>\n",
       "      <td>3346</td>\n",
       "      <td>2014-04-30 23:39:59</td>\n",
       "      <td>3346</td>\n",
       "      <td>2014-04-30 23:40:00</td>\n",
       "      <td>3359</td>\n",
       "      <td>2014-04-30 23:40:05</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-04-30 23:40:05</td>\n",
       "      <td>3346</td>\n",
       "      <td>2014-04-30 23:40:05</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        session_id  site1               time1  site2               time2  \\\n",
       "12223        12224     50 2014-04-30 23:33:48     50 2014-04-30 23:33:49   \n",
       "164437      164438   4207 2014-04-30 23:34:15    753 2014-04-30 23:34:16   \n",
       "12220        12221     52 2014-04-30 23:38:08   3346 2014-04-30 23:38:10   \n",
       "156967      156968   3328 2014-04-30 23:38:36   3324 2014-04-30 23:38:36   \n",
       "204761      204762    222 2014-04-30 23:39:53   3346 2014-04-30 23:39:59   \n",
       "\n",
       "        site3               time3  site4               time4  site5   ...    \\\n",
       "12223      48 2014-04-30 23:33:52     49 2014-04-30 23:33:52     48   ...     \n",
       "164437    753 2014-04-30 23:34:17     52 2014-04-30 23:34:18     50   ...     \n",
       "12220     784 2014-04-30 23:38:13    784 2014-04-30 23:38:18   3346   ...     \n",
       "156967   3599 2014-04-30 23:38:38   3413 2014-04-30 23:38:38    753   ...     \n",
       "204761   3346 2014-04-30 23:40:00   3359 2014-04-30 23:40:05     55   ...     \n",
       "\n",
       "                     time6  site7               time7  site8  \\\n",
       "12223  2014-04-30 23:33:53     52 2014-04-30 23:33:54     49   \n",
       "164437 2014-04-30 23:35:16   3346 2014-04-30 23:35:29   3359   \n",
       "12220  2014-04-30 23:38:24   3324 2014-04-30 23:38:35   7330   \n",
       "156967 2014-04-30 23:38:40   3599 2014-04-30 23:38:40   3359   \n",
       "204761 2014-04-30 23:40:05   3346 2014-04-30 23:40:05      0   \n",
       "\n",
       "                     time8  site9               time9  site10  \\\n",
       "12223  2014-04-30 23:33:54    303 2014-04-30 23:33:57     304   \n",
       "164437 2014-04-30 23:36:12   3346 2014-04-30 23:36:42      38   \n",
       "12220  2014-04-30 23:38:35   3594 2014-04-30 23:38:35    3329   \n",
       "156967 2014-04-30 23:39:07   3359 2014-04-30 23:39:08    3346   \n",
       "204761                 NaT      0                 NaT       0   \n",
       "\n",
       "                    time10  target  \n",
       "12223  2014-04-30 23:34:00       0  \n",
       "164437 2014-04-30 23:37:13       0  \n",
       "12220  2014-04-30 23:38:36       0  \n",
       "156967 2014-04-30 23:39:53       0  \n",
       "204761                 NaT       0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_df = train_df['target']\n",
    "train_df = train_df.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>site1</th>\n",
       "      <th>time1</th>\n",
       "      <th>site2</th>\n",
       "      <th>time2</th>\n",
       "      <th>site3</th>\n",
       "      <th>time3</th>\n",
       "      <th>site4</th>\n",
       "      <th>time4</th>\n",
       "      <th>site5</th>\n",
       "      <th>...</th>\n",
       "      <th>site6</th>\n",
       "      <th>time6</th>\n",
       "      <th>site7</th>\n",
       "      <th>time7</th>\n",
       "      <th>site8</th>\n",
       "      <th>time8</th>\n",
       "      <th>site9</th>\n",
       "      <th>time9</th>\n",
       "      <th>site10</th>\n",
       "      <th>time10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82792</th>\n",
       "      <td>82793</td>\n",
       "      <td>812</td>\n",
       "      <td>2014-10-02 18:20:09</td>\n",
       "      <td>1039</td>\n",
       "      <td>2014-10-02 18:20:09</td>\n",
       "      <td>676</td>\n",
       "      <td>2014-10-02 18:20:09</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82793</th>\n",
       "      <td>82794</td>\n",
       "      <td>300</td>\n",
       "      <td>2014-05-26 14:16:40</td>\n",
       "      <td>302</td>\n",
       "      <td>2014-05-26 14:16:41</td>\n",
       "      <td>302</td>\n",
       "      <td>2014-05-26 14:16:44</td>\n",
       "      <td>300</td>\n",
       "      <td>2014-05-26 14:16:44</td>\n",
       "      <td>300</td>\n",
       "      <td>...</td>\n",
       "      <td>1222</td>\n",
       "      <td>2014-05-26 14:17:19</td>\n",
       "      <td>302</td>\n",
       "      <td>2014-05-26 14:17:19</td>\n",
       "      <td>1218</td>\n",
       "      <td>2014-05-26 14:17:19</td>\n",
       "      <td>1221</td>\n",
       "      <td>2014-05-26 14:17:19</td>\n",
       "      <td>1216</td>\n",
       "      <td>2014-05-26 14:17:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82794</th>\n",
       "      <td>82795</td>\n",
       "      <td>29</td>\n",
       "      <td>2014-05-02 11:21:56</td>\n",
       "      <td>33</td>\n",
       "      <td>2014-05-02 11:21:56</td>\n",
       "      <td>35</td>\n",
       "      <td>2014-05-02 11:21:56</td>\n",
       "      <td>22</td>\n",
       "      <td>2014-05-02 11:22:03</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>6779</td>\n",
       "      <td>2014-05-02 11:22:03</td>\n",
       "      <td>30</td>\n",
       "      <td>2014-05-02 11:22:03</td>\n",
       "      <td>21</td>\n",
       "      <td>2014-05-02 11:22:04</td>\n",
       "      <td>23</td>\n",
       "      <td>2014-05-02 11:22:04</td>\n",
       "      <td>6780</td>\n",
       "      <td>2014-05-02 11:22:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82795</th>\n",
       "      <td>82796</td>\n",
       "      <td>5828</td>\n",
       "      <td>2014-05-03 10:05:25</td>\n",
       "      <td>23</td>\n",
       "      <td>2014-05-03 10:05:27</td>\n",
       "      <td>21</td>\n",
       "      <td>2014-05-03 10:05:27</td>\n",
       "      <td>804</td>\n",
       "      <td>2014-05-03 10:05:27</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>3350</td>\n",
       "      <td>2014-05-03 10:05:37</td>\n",
       "      <td>23</td>\n",
       "      <td>2014-05-03 10:05:37</td>\n",
       "      <td>894</td>\n",
       "      <td>2014-05-03 10:05:38</td>\n",
       "      <td>21</td>\n",
       "      <td>2014-05-03 10:05:38</td>\n",
       "      <td>961</td>\n",
       "      <td>2014-05-03 10:05:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82796</th>\n",
       "      <td>82797</td>\n",
       "      <td>21</td>\n",
       "      <td>2014-11-02 10:46:57</td>\n",
       "      <td>1098</td>\n",
       "      <td>2014-11-02 10:46:57</td>\n",
       "      <td>1098</td>\n",
       "      <td>2014-11-02 10:46:58</td>\n",
       "      <td>1098</td>\n",
       "      <td>2014-11-02 10:47:12</td>\n",
       "      <td>1098</td>\n",
       "      <td>...</td>\n",
       "      <td>1098</td>\n",
       "      <td>2014-11-02 10:47:14</td>\n",
       "      <td>1098</td>\n",
       "      <td>2014-11-02 10:47:15</td>\n",
       "      <td>1098</td>\n",
       "      <td>2014-11-02 10:47:18</td>\n",
       "      <td>1098</td>\n",
       "      <td>2014-11-02 10:47:42</td>\n",
       "      <td>1098</td>\n",
       "      <td>2014-11-02 10:47:47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       session_id  site1               time1  site2               time2  \\\n",
       "82792       82793    812 2014-10-02 18:20:09   1039 2014-10-02 18:20:09   \n",
       "82793       82794    300 2014-05-26 14:16:40    302 2014-05-26 14:16:41   \n",
       "82794       82795     29 2014-05-02 11:21:56     33 2014-05-02 11:21:56   \n",
       "82795       82796   5828 2014-05-03 10:05:25     23 2014-05-03 10:05:27   \n",
       "82796       82797     21 2014-11-02 10:46:57   1098 2014-11-02 10:46:57   \n",
       "\n",
       "       site3               time3  site4               time4  site5  \\\n",
       "82792    676 2014-10-02 18:20:09      0                 NaT      0   \n",
       "82793    302 2014-05-26 14:16:44    300 2014-05-26 14:16:44    300   \n",
       "82794     35 2014-05-02 11:21:56     22 2014-05-02 11:22:03     37   \n",
       "82795     21 2014-05-03 10:05:27    804 2014-05-03 10:05:27     21   \n",
       "82796   1098 2014-11-02 10:46:58   1098 2014-11-02 10:47:12   1098   \n",
       "\n",
       "              ...         site6               time6 site7               time7  \\\n",
       "82792         ...             0                 NaT     0                 NaT   \n",
       "82793         ...          1222 2014-05-26 14:17:19   302 2014-05-26 14:17:19   \n",
       "82794         ...          6779 2014-05-02 11:22:03    30 2014-05-02 11:22:03   \n",
       "82795         ...          3350 2014-05-03 10:05:37    23 2014-05-03 10:05:37   \n",
       "82796         ...          1098 2014-11-02 10:47:14  1098 2014-11-02 10:47:15   \n",
       "\n",
       "      site8               time8 site9               time9 site10  \\\n",
       "82792     0                 NaT     0                 NaT      0   \n",
       "82793  1218 2014-05-26 14:17:19  1221 2014-05-26 14:17:19   1216   \n",
       "82794    21 2014-05-02 11:22:04    23 2014-05-02 11:22:04   6780   \n",
       "82795   894 2014-05-03 10:05:38    21 2014-05-03 10:05:38    961   \n",
       "82796  1098 2014-11-02 10:47:18  1098 2014-11-02 10:47:42   1098   \n",
       "\n",
       "                   time10  \n",
       "82792                 NaT  \n",
       "82793 2014-05-26 14:17:19  \n",
       "82794 2014-05-02 11:22:04  \n",
       "82795 2014-05-03 10:05:38  \n",
       "82796 2014-11-02 10:47:47  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "всего сайтов: 48371\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "with open(r\"../../data/intruder/site_dic.pkl\", \"rb\") as input_file:\n",
    "    site_dict = pickle.load(input_file)\n",
    "\n",
    "# датафрейм словарика сайтов\n",
    "sites_dict = pd.DataFrame(list(site_dict.keys()), index=list(site_dict.values()), columns=['site'])\n",
    "print(u'всего сайтов:', sites_dict.shape[0])\n",
    "sites_dict.head()\n",
    "\n",
    "print (sites_dict.index.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to sites sparse and times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_sites_cv = TfidfVectorizer(tokenizer=lambda x: [str(el) for el in x], ngram_range=(1, 3), lowercase=False, sublinear_tf=True, max_df=0.6, norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df_sites = full_sites_cv.fit_transform(train_df[sites].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df_sites = full_sites_cv.transform(test_df[sites].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 848826)\t0.181188614606\n",
      "  (0, 836761)\t0.176403588498\n",
      "  (0, 0)\t0.479982016485\n",
      "  (0, 849960)\t0.196025359334\n",
      "  (0, 836762)\t0.269644167853\n",
      "  (0, 1)\t0.471864946714\n",
      "  (0, 849961)\t0.290760064542\n",
      "  (0, 836763)\t0.273171629213\n",
      "  (0, 2)\t0.461210497406\n",
      "  (1, 848826)\t0.268072117002\n",
      "  (1, 836761)\t0.260992576814\n",
      "  (1, 0)\t0.380239322662\n",
      "  (1, 849960)\t0.290023372479\n",
      "  (1, 836762)\t0.235622662587\n",
      "  (1, 1)\t0.365234013337\n",
      "  (1, 849961)\t0.254074327388\n",
      "  (1, 836763)\t0.238705057598\n",
      "  (1, 2)\t0.344485723828\n",
      "  (1, 840076)\t0.199373367748\n",
      "  (1, 850363)\t0.332605898554\n",
      "  (1, 840296)\t0.227662220028\n",
      "  (2, 1043409)\t0.378119864476\n",
      "  (2, 1045108)\t0.149641318738\n",
      "  (2, 1043228)\t0.16400925607\n",
      "  (2, 1044386)\t0.114370946745\n",
      "  :\t:\n",
      "  (253559, 951205)\t0.23998157936\n",
      "  (253559, 605065)\t0.23998157936\n",
      "  (253559, 655748)\t0.23998157936\n",
      "  (253560, 836761)\t0.0824240884812\n",
      "  (253560, 0)\t0.152838212889\n",
      "  (253560, 1)\t0.126718396547\n",
      "  (253560, 2)\t0.0771912232282\n",
      "  (253560, 341683)\t0.105889334906\n",
      "  (253560, 607600)\t0.298565768873\n",
      "  (253560, 607869)\t0.167779280125\n",
      "  (253560, 611840)\t0.163898649208\n",
      "  (253560, 607932)\t0.180062057666\n",
      "  (253560, 607897)\t0.198989593733\n",
      "  (253560, 607601)\t0.196014824736\n",
      "  (253560, 607602)\t0.197285921323\n",
      "  (253560, 485307)\t0.185895648875\n",
      "  (253560, 611996)\t0.247999063923\n",
      "  (253560, 342782)\t0.251879694841\n",
      "  (253560, 342783)\t0.262752384522\n",
      "  (253560, 838448)\t0.215211396035\n",
      "  (253560, 485338)\t0.271382523833\n",
      "  (253560, 607953)\t0.271382523833\n",
      "  (253560, 611997)\t0.271382523833\n",
      "  (253560, 838456)\t0.271382523833\n",
      "  (253560, 485339)\t0.271382523833\n"
     ]
    }
   ],
   "source": [
    "print (train_df_sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "times_train_engineered = pd.DataFrame(index=train_df.index)\n",
    "times_train_engineered['start_month'] = train_df['time1'].apply(lambda ts: 100 * ts.year + ts.month)\n",
    "times_train_engineered['start_hour'] = train_df['time1'].apply(lambda ts: ts.hour)\n",
    "times_train_engineered['morning'] = train_df['time1'].apply(lambda ts: int(ts.hour <= 12))\n",
    "#times_train_engineered['session_length'] = train_df[times].apply(lambda x: (np.max(x) - np.min(x)) / np.timedelta64(1, 's'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#times_train_engineered['lunch_time'] = train_df['time1'].apply(lambda ts: int(ts.hour >= 15 and ts.hour <= 16))\n",
    "times_train_engineered['weekend'] = train_df['time1'].apply(lambda ts: int(ts.dayofweek == 5 or ts.dayofweek == 6))\n",
    "#times_train_engineered['mon_tue'] = train_df['time1'].apply(lambda ts: int(ts.dayofweek == 0 or ts.dayofweek == 1))\n",
    "#times_train_engineered['night'] = train_df['time1'].apply(lambda ts: int(ts.hour >= 22 or ts.hour <= 3))\n",
    "#times_train_engineered['day'] = train_df['time1'].apply(lambda ts: int(ts.hour >= 13 and ts.hour <= 18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_month</th>\n",
       "      <th>start_hour</th>\n",
       "      <th>morning</th>\n",
       "      <th>weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21668</th>\n",
       "      <td>201301</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54842</th>\n",
       "      <td>201301</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77291</th>\n",
       "      <td>201301</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114020</th>\n",
       "      <td>201301</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146669</th>\n",
       "      <td>201301</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        start_month  start_hour  morning  weekend\n",
       "21668        201301           8        1        1\n",
       "54842        201301           8        1        1\n",
       "77291        201301           8        1        1\n",
       "114020       201301           8        1        1\n",
       "146669       201301           8        1        1"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times_train_engineered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "times_test_engineered = pd.DataFrame(index=test_df.index)\n",
    "times_test_engineered['start_month'] = test_df['time1'].apply(lambda ts: 100 * ts.year + ts.month)\n",
    "times_test_engineered['start_hour'] = test_df['time1'].apply(lambda ts: ts.hour)\n",
    "times_test_engineered['morning'] = test_df['time1'].apply(lambda ts: int(ts.hour <= 12))\n",
    "#times_test_engineered['session_length'] = test_df[times].apply(lambda x: (np.max(x) - np.min(x)) / np.timedelta64(1, 's'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#times_test_engineered['lunch_time'] = test_df['time1'].apply(lambda ts: int(ts.hour >= 15 and ts.hour <= 16))\n",
    "times_test_engineered['weekend'] = test_df['time1'].apply(lambda ts: int(ts.dayofweek == 5 or ts.dayofweek == 6))\n",
    "#times_test_engineered['mon_tue'] = test_df['time1'].apply(lambda ts: int(ts.dayofweek == 0 or ts.dayofweek == 1))\n",
    "#times_test_engineered['night'] = test_df['time1'].apply(lambda ts: int(ts.hour >= 22 or ts.hour <= 3))\n",
    "#times_test_engineered['day'] = test_df['time1'].apply(lambda ts: int(ts.hour >= 13 and ts.hour <= 18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_month</th>\n",
       "      <th>start_hour</th>\n",
       "      <th>morning</th>\n",
       "      <th>weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201410</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201407</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201412</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201411</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201405</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_month  start_hour  morning  weekend\n",
       "0       201410          11        1        1\n",
       "1       201407          11        1        0\n",
       "2       201412          15        0        0\n",
       "3       201411          10        1        0\n",
       "4       201405          15        0        0"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times_test_engineered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "times_train_engineered_scaled = scaler.fit_transform(times_train_engineered)\n",
    "times_test_engineered_scaled = scaler.transform(times_test_engineered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_train = csr_matrix(hstack([times_train_engineered_scaled, train_df_sites]))\n",
    "full_test = csr_matrix(hstack([times_test_engineered_scaled, test_df_sites]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253561, 1060072)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we're working with time series data so no way we could use CV split\n",
    "#X_train_sites, X_valid_sites, y_train, y_valid = train_test_split(full_train, y_train_df, test_size = 0.1)\n",
    "idx = round(full_train.shape[0] * 0.9)\n",
    "X_train = full_train[:idx, :]\n",
    "X_valid = full_train[idx:, :]\n",
    "\n",
    "y_train = y_train_df[:idx]\n",
    "y_valid = y_train_df[idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-df4d05257f27>\u001b[0m in \u001b[0;36mget_auc_lr_valid\u001b[0;34m(X, y, C, ratio)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# обучение классификатора\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m# прогноз для валидационной выборки\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/borowis/.pyenv/versions/anaconda3-4.1.1/lib/python3.5/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m                 sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/borowis/.pyenv/versions/anaconda3-4.1.1/lib/python3.5/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m         epsilon, sample_weight)\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m     \u001b[0;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Cs = [1]\n",
    "scores = []\n",
    "\n",
    "Cs = np.linspace(6.5, 8, num=20)\n",
    "for C in tqdm(Cs):\n",
    "    scores.append(get_auc_lr_valid(X_train, y_train, C=C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#C_best = Cs[np.argmax(scores)]\n",
    "C_best = 4\n",
    "lr = LogisticRegression(C=C_best, n_jobs=-1).fit(X_train, y_train)\n",
    "#br = BaggingClassifier(lr, n_estimators=20, max_samples=0.8, max_features=0.8).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.996345239352\n",
      "0.967462163481\n"
     ]
    }
   ],
   "source": [
    "print (roc_auc_score(y_train, lr.predict_proba(X_train)[:,1]))\n",
    "print (roc_auc_score(y_valid, lr.predict_proba(X_valid)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25083,     9],\n",
       "       [  252,    12]])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid_predictions = lr.predict(X_valid)\n",
    "confusion_matrix(y_valid, y_valid_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_auc_xgb_valid(X, y, max_delta_step, min_child_weight, max_depth, gamma, ratio=0.9):\n",
    "    # разделим выборку на обучающую и валидационную\n",
    "    idx = round(X.shape[0] * ratio)\n",
    "\n",
    "    # обучение классификатора\n",
    "    xgbc = xgb.XGBClassifier(objective='binary:logistic', n_estimators=150, \\\n",
    "                             max_delta_step=max_delta_step, gamma=gamma, min_child_weight=min_child_weight, \\\n",
    "                             max_depth=max_depth)\n",
    "    \n",
    "    xgbc.fit(X[:idx, :], y[:idx], eval_metric='auc')\n",
    "\n",
    "    # прогноз для валидационной выборки\n",
    "    y_pred = xgbc.predict_proba(X[idx:, :])[:, 1]\n",
    "    \n",
    "    # считаем качество\n",
    "    score = roc_auc_score(y[idx:], y_pred)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta: 3, min_child_weight: 1, max_depth: 3, gamma: 0.000 --> score: 0.9603634872515853\n",
      "delta: 3, min_child_weight: 1, max_depth: 5, gamma: 0.000 --> score: 0.9609752793521080\n",
      "delta: 3, min_child_weight: 1, max_depth: 7, gamma: 0.000 --> score: 0.9594595287260371\n",
      "delta: 3, min_child_weight: 1, max_depth: 9, gamma: 0.000 --> score: 0.9612619539270391\n",
      "delta: 3, min_child_weight: 3, max_depth: 3, gamma: 0.000 --> score: 0.9596967766501179\n",
      "delta: 3, min_child_weight: 3, max_depth: 5, gamma: 0.000 --> score: 0.9601756659783548\n",
      "delta: 3, min_child_weight: 3, max_depth: 7, gamma: 0.000 --> score: 0.9584977227128275\n",
      "delta: 3, min_child_weight: 3, max_depth: 9, gamma: 0.000 --> score: 0.9584523234187134\n",
      "delta: 3, min_child_weight: 5, max_depth: 3, gamma: 0.000 --> score: 0.9569614691797372\n",
      "delta: 3, min_child_weight: 5, max_depth: 5, gamma: 0.000 --> score: 0.9598315100391019\n",
      "delta: 3, min_child_weight: 5, max_depth: 7, gamma: 0.000 --> score: 0.9607808678587643\n",
      "delta: 3, min_child_weight: 5, max_depth: 9, gamma: 0.000 --> score: 0.9591168372801430\n",
      "delta: 4, min_child_weight: 1, max_depth: 3, gamma: 0.000 --> score: 0.9601760321016943\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "scores = []\n",
    "\n",
    "for max_delta_step in range (3, 7, 1):\n",
    "    for min_child_weight in range(1, 6, 2):\n",
    "        for max_depth in range(3, 10, 2):\n",
    "            new_sc = get_auc_xgb_valid(X_train, y_train, max_delta_step, min_child_weight, max_depth, 0)\n",
    "                \n",
    "            print (\"delta: %d, min_child_weight: %d, max_depth: %d, gamma: %5.3f --> score: %2.16f\" % \\\n",
    "                  (max_delta_step, min_child_weight, max_depth, 0, new_sc))                \n",
    "                \n",
    "            scores.append(new_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgbc_best = xgb.XGBClassifier(objective='binary:logistic', n_estimators=150, \\\n",
    "    max_delta_step=5, gamma=0, min_child_weight=1, \\\n",
    "    max_depth=5).fit(X_train, y_train, eval_metric='auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.992597896517\n",
      "0.987138693245\n"
     ]
    }
   ],
   "source": [
    "print (roc_auc_score(y_train, xgbc_best.predict_proba(X_train)[:, 1]))\n",
    "print (roc_auc_score(y_valid, xgbc_best.predict_proba(X_valid)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25053,    39],\n",
       "       [  185,    79]])"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid_predictions = xgbc_best.predict(X_valid)\n",
    "confusion_matrix(y_valid, y_valid_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_insights(indcs, df):\n",
    "    # actionable df\n",
    "    act_df = pd.DataFrame(df.iloc[indcs])\n",
    "    act_df['dow'] = act_df['time1'].apply(lambda ts: int(ts.dayofweek))\n",
    "    act_df['hour'] = act_df['time1'].apply(lambda ts: int(ts.hour))\n",
    "    act_df['min'] = act_df[times].min(axis=1)\n",
    "    act_df['max'] = act_df[times].max(axis=1)\n",
    "    act_df['seconds'] = (act_df['max'] - act_df['min']) / np.timedelta64(1, 's')\n",
    "\n",
    "    # top sites\n",
    "    top_sites = pd.Series(act_df[sites].values.flatten()).value_counts().sort_values(ascending=False).head(10)\n",
    "    print (sites_dict.ix[top_sites.index])\n",
    "    \n",
    "    # day of week and start time\n",
    "    print (\"\\ndow, start time\")\n",
    "    print (pd.Series(act_df['dow'].values.flatten()).value_counts().sort_values(ascending=False).head())\n",
    "    print ()\n",
    "    print (pd.Series(act_df['hour'].values.flatten()).value_counts().sort_values(ascending=False).head())\n",
    "    \n",
    "    # \n",
    "    print (\"\\nsession length\")\n",
    "    print (pd.Series(act_df['seconds'].values.flatten()).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       site\n",
      "0                       NaN\n",
      "782          annotathon.org\n",
      "21            www.google.fr\n",
      "23           www.google.com\n",
      "786        www.phylogeny.fr\n",
      "22          apis.google.com\n",
      "167            www.bing.com\n",
      "52      clients1.google.com\n",
      "29         www.facebook.com\n",
      "302  ent.univ-bpclermont.fr\n",
      "\n",
      "dow, start time\n",
      "4    7084\n",
      "3    5543\n",
      "2    4471\n",
      "0    4272\n",
      "1    2939\n",
      "dtype: int64\n",
      "\n",
      "14    3365\n",
      "13    2935\n",
      "11    2769\n",
      "10    2753\n",
      "15    2351\n",
      "dtype: int64\n",
      "\n",
      "session length\n",
      "count    24828.000000\n",
      "mean       151.112293\n",
      "std        310.956469\n",
      "min          0.000000\n",
      "25%          6.000000\n",
      "50%         31.000000\n",
      "75%        131.000000\n",
      "max       1800.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# true positives\n",
    "get_insights(np.where((y_valid == y_valid_predictions) & (y_valid == 0))[0] + idx, train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     site\n",
      "77                           i1.ytimg.com\n",
      "76                        www.youtube.com\n",
      "75                            s.ytimg.com\n",
      "78                          yt3.ggpht.com\n",
      "80                          s.youtube.com\n",
      "617                         gg.google.com\n",
      "22                        apis.google.com\n",
      "81   r4---sn-gxo5uxg-jqbe.googlevideo.com\n",
      "82   r2---sn-gxo5uxg-jqbe.googlevideo.com\n",
      "881  r3---sn-gxo5uxg-jqbe.googlevideo.com\n",
      "\n",
      "dow, start time\n",
      "0    68\n",
      "1    39\n",
      "dtype: int64\n",
      "\n",
      "16    58\n",
      "17    39\n",
      "18     8\n",
      "15     2\n",
      "dtype: int64\n",
      "\n",
      "session length\n",
      "count     107.000000\n",
      "mean       64.130841\n",
      "std       165.581484\n",
      "min         1.000000\n",
      "25%         6.000000\n",
      "50%        12.000000\n",
      "75%        59.000000\n",
      "max      1522.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# true negatives\n",
    "get_insights(np.where((y_valid == y_valid_predictions) & (y_valid == 1))[0] + idx, train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      site\n",
      "77                            i1.ytimg.com\n",
      "76                         www.youtube.com\n",
      "617                          gg.google.com\n",
      "80                           s.youtube.com\n",
      "81    r4---sn-gxo5uxg-jqbe.googlevideo.com\n",
      "879   r1---sn-gxo5uxg-jqbe.googlevideo.com\n",
      "82    r2---sn-gxo5uxg-jqbe.googlevideo.com\n",
      "1307              www.youtube-nocookie.com\n",
      "881   r3---sn-gxo5uxg-jqbe.googlevideo.com\n",
      "78                           yt3.ggpht.com\n",
      "\n",
      "dow, start time\n",
      "1    9\n",
      "dtype: int64\n",
      "\n",
      "17    5\n",
      "16    4\n",
      "dtype: int64\n",
      "\n",
      "session length\n",
      "count      9.000000\n",
      "mean     179.777778\n",
      "std      147.420129\n",
      "min        3.000000\n",
      "25%       55.000000\n",
      "50%      184.000000\n",
      "75%      267.000000\n",
      "max      461.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# false negatives : true value 0, predicted 1\n",
    "get_insights(np.where((y_valid != y_valid_predictions) & (y_valid == 0))[0] + idx, train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       site\n",
      "77                             i1.ytimg.com\n",
      "76                          www.youtube.com\n",
      "75                              s.ytimg.com\n",
      "37                              twitter.com\n",
      "22                          apis.google.com\n",
      "29                         www.facebook.com\n",
      "78                            yt3.ggpht.com\n",
      "80                            s.youtube.com\n",
      "881    r3---sn-gxo5uxg-jqbe.googlevideo.com\n",
      "25383               www.cjn.justice.gouv.fr\n",
      "\n",
      "dow, start time\n",
      "0    156\n",
      "1     84\n",
      "dtype: int64\n",
      "\n",
      "17    114\n",
      "16    106\n",
      "18     14\n",
      "15      6\n",
      "dtype: int64\n",
      "\n",
      "session length\n",
      "count     240.000000\n",
      "mean       42.725000\n",
      "std       124.057448\n",
      "min         0.000000\n",
      "25%         5.000000\n",
      "50%        11.500000\n",
      "75%        40.000000\n",
      "max      1522.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# false positives: true value 1, predicted 0\n",
    "get_insights(np.where((y_valid != y_valid_predictions) & (y_valid == 1))[0] + idx, train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_best = LogisticRegression(C=C_best).fit(full_train, y_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "br_best = br.fit(full_train, y_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgbc_best = xgb.XGBClassifier(objective='binary:logistic', n_estimators=150, \\\n",
    "    max_delta_step=5, gamma=0, min_child_weight=1, max_depth=5).fit(full_train, y_train_df, eval_metric='auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = lr_best.predict_proba(full_test)[:, 1]\n",
    "#y_pred = xgbc_best.predict_proba(full_test)[:, 1]\n",
    "write_to_submission_file(y_pred, 'baseline1.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
