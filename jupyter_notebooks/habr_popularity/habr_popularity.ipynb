{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and common functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import json\n",
    "import glob\n",
    "import re\n",
    "\n",
    "from pandas.io.json import json_normalize\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepareForVWFormat(namespace_name, feature):\n",
    "    processedFeature = feature\n",
    "    if isinstance(feature, pd.Series):\n",
    "        processedFeature = feature[0]\n",
    "\n",
    "    if not processedFeature:\n",
    "        processedFeature = '-'\n",
    "    \n",
    "    # can't be used in feature or namespace names are vertical bar, colon, space, and newline\n",
    "    ns_processed = namespace_name.strip().replace(\":\", \"\").replace(\"|\", \"\").replace(\",\", \"\")\n",
    "    f_processed = processedFeature.strip().replace(\":\", \"\").replace(\"|\", \"\").replace(\",\", \"\").replace(\"\\n\", \" \")\n",
    "\n",
    "    return \"|\" + ns_processed + \" \" + f_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processText(text):\n",
    "    processedText = text\n",
    "    if isinstance(text, pd.Series):\n",
    "        processedText = text[0]\n",
    "        \n",
    "    if not processedText:\n",
    "        return '-'\n",
    "    \n",
    "    return re.sub(r'[^\\w\\s]', '', processedText.strip().lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertDomain(domain):\n",
    "    processedDomain = domain\n",
    "    if isinstance(domain, pd.Series):\n",
    "        processedDomain = domain[0]\n",
    "\n",
    "    if not processedDomain:\n",
    "        return '-'\n",
    "    \n",
    "    return '0' if re.match(\"^habr.*\", processedDomain) else '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stripHtml(text):\n",
    "    processedText = text\n",
    "    if isinstance(text, pd.Series):\n",
    "        processedText = text[0]\n",
    "        \n",
    "    if not processedText:\n",
    "        return '-'\n",
    "\n",
    "    return re.sub('<[^>]*>', '', processedText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertToVWFormat(json_obj):\n",
    "    author_name = processText(json_obj['author.name'])\n",
    "    author_nickname = processText(json_obj['author.nickname'])\n",
    "    content = processText(stripHtml(json_obj['content']))\n",
    "    domain = convertDomain(json_obj['domain'])\n",
    "    title = processText(stripHtml(json_obj['title']))\n",
    "    flow = processText(json_obj['flow'])\n",
    "    \n",
    "    tags = processText(None if not json_obj['tags'][0] else ' '.join(json_obj['tags'][0]))\n",
    "    hubs = processText(None if not json_obj['hubs'][0] else ' '.join([el['id'] for el in json_obj['hubs'][0]]))\n",
    "    \n",
    "    if not json_obj['published.$date'][0]:\n",
    "        hour = '-'\n",
    "        dow = '-'\n",
    "    else:\n",
    "        publication_date = pd.to_datetime(json_obj['published.$date'])[0]\n",
    "        hour = str(publication_date.hour)\n",
    "        dow = str(publication_date.dayofweek)\n",
    "    \n",
    "    \n",
    "    return str(json_obj['post_id'][0]) + prepareForVWFormat('author_name', author_name) + \\\n",
    "        prepareForVWFormat('author_nickname', author_nickname) + prepareForVWFormat('content', content) + \\\n",
    "        prepareForVWFormat('domain', domain) + prepareForVWFormat('title', title) + \\\n",
    "        prepareForVWFormat('tags', tags) + prepareForVWFormat('hubs', hubs) + \\\n",
    "        prepareForVWFormat('flow', flow) + prepareForVWFormat('hour', hour) + \\\n",
    "        prepareForVWFormat('dow', dow) + \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data extraction and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.6 s, sys: 1.54 s, total: 39.2 s\n",
      "Wall time: 42.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "f_test_vw = open('../../data/habr_popularity/test.vw', 'w')\n",
    "for file in glob.glob('../../data/habr_popularity/test/*.json'):\n",
    "    json_obj = json_normalize(json.loads(open(file).read()))\n",
    "    f_test_vw.write(convertToVWFormat(json_obj))\n",
    "    \n",
    "f_test_vw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = pd.read_csv('../../data/habr_popularity/train_target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.6931471805599453'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'%2.16f' % (results[results['_id'] == 'https://geektimes.ru/post/8/']['favs_lognorm']).values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 13min 49s, sys: 54.8 s, total: 1h 14min 44s\n",
      "Wall time: 1h 16min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "f_train_vw = open('../../data/habr_popularity/train.vw', 'w')\n",
    "for file in glob.glob('../../data/habr_popularity/train/*.json'):\n",
    "    json_obj = json_normalize(json.loads(open(file).read()))\n",
    "    target = '%2.16f' % (results[results['_id'] == json_obj['_id'][0]]['favs_lognorm']).values[0]\n",
    "    f_train_vw.write(target + ' ' + convertToVWFormat(json_obj))\n",
    "    \n",
    "f_train_vw.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172913 ../../data/habr_popularity/train.vw\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l ../../data/habr_popularity/train.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!split -l138330 ../../data/habr_popularity/train.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 3099656\r\n",
      "drwxrwxr-x 4 borowis borowis       4096 May 29 12:00 .\r\n",
      "drwxrwxr-x 7 borowis borowis      12288 May 23 23:06 ..\r\n",
      "-rw-rw-r-- 1 borowis borowis    2624681 May 29 12:00 model_1_1.vw\r\n",
      "drwxr-xr-x 2 borowis borowis     716800 Apr 29 10:11 test\r\n",
      "-rw-rw-r-- 1 borowis borowis      86480 May 29 11:47 test_1_1.predictions\r\n",
      "-rw-rw-r-- 1 borowis borowis   91924254 May 29 00:13 test.vw\r\n",
      "drwxr-xr-x 2 borowis borowis   23236608 Apr 29 10:11 train\r\n",
      "-rw-rw-r-- 1 borowis borowis    9340760 May 23 23:08 train_target.csv\r\n",
      "-rw-rw-r-- 1 borowis borowis 1522705530 May 29 01:37 train.vw\r\n",
      "-rw-rw-r-- 1 borowis borowis     536415 May 29 12:00 valid_1_1.predictions\r\n",
      "-rw-rw-r-- 1 borowis borowis 1216306113 May 29 11:57 xaa\r\n",
      "-rw-rw-r-- 1 borowis borowis  306399417 May 29 11:57 xab\r\n"
     ]
    }
   ],
   "source": [
    "!ls -al ../../data/habr_popularity/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cut -d \" \" -f1 ../../data/habr_popularity/xab > ../../data/habr_popularity/xab_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vw first solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 2-grams for c namespaces.\n",
      "Generating 2-grams for t namespaces.\n",
      "final_regressor = ../../data/habr_popularity/model_1_1.vw\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = ../../data/habr_popularity/xaa.cache\n",
      "Reading datafile = ../../data/habr_popularity/xaa\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.921812 1.921812            1            1.0   1.3863   0.0000      102\n",
      "1.912189 1.902566            2            2.0   1.3863   0.0070       56\n",
      "3.362879 4.813568            4            4.0   2.7081   0.1465       74\n",
      "3.624586 3.886292            8            8.0   0.6931   0.8101      121\n",
      "7.405031 11.185476           16           16.0   3.9890   0.2537       19\n",
      "8.612327 9.819623           32           32.0   5.8636   0.8375       59\n",
      "6.967297 5.322268           64           64.0   4.9767   0.5129        6\n",
      "6.257537 5.547777          128          128.0   4.2195   2.1031       86\n",
      "5.248163 4.238788          256          256.0   0.6931   0.9072       21\n",
      "4.514381 3.780599          512          512.0   1.6094   1.0431        5\n",
      "4.096870 3.679360         1024         1024.0   4.3307   1.0477        4\n",
      "3.625558 3.154246         2048         2048.0   4.4308   3.1441      107\n",
      "3.137198 2.648838         4096         4096.0   3.8501   3.0485       13\n",
      "2.762166 2.387135         8192         8192.0   2.3979   1.9074       67\n",
      "2.495438 2.228709        16384        16384.0   2.8332   3.0113       88\n",
      "2.257979 2.020520        32768        32768.0   4.3307   2.6471       97\n",
      "2.084360 1.910742        65536        65536.0   4.5326   3.7767       40\n"
     ]
    }
   ],
   "source": [
    "!vw -c -k --passes 5 --ngram c2 --ngram t2 --hash strings --bootstrap 10 -d ../../data/habr_popularity/xaa -b 28 -f ../../data/habr_popularity/model_1_1.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = ../../data/habr_popularity/model_1_1.vw\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = ../../data/habr_popularity/xaa\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.921812 1.921812            1            1.0   1.3863   0.0000       53\n",
      "1.886483 1.851155            2            2.0   1.3863   0.0257       30\n",
      "3.139852 4.393220            4            4.0   2.7081   0.2815       39\n",
      "3.207326 3.274800            8            8.0   0.6931   1.5959       63\n",
      "5.181009 7.154692           16           16.0   4.6913   0.3193        5\n",
      "6.367646 7.554283           32           32.0   0.0000   2.7423       62\n",
      "5.511507 4.655369           64           64.0   1.0986   0.9815        5\n",
      "5.245319 4.979130          128          128.0   4.9273   1.8337       43\n",
      "4.539271 3.833224          256          256.0   3.1781   2.5392       49\n",
      "3.908689 3.278106          512          512.0   4.9698   2.6096       38\n",
      "3.498360 3.088032         1024         1024.0   0.6931   2.0266       10\n",
      "3.102539 2.706717         2048         2048.0   4.9416   4.6937       79\n",
      "2.664825 2.227111         4096         4096.0   4.2627   2.7087        6\n",
      "2.423785 2.182746         8192         8192.0   3.7136   3.2134       26\n",
      "2.244239 2.064693        16384        16384.0   2.0794   2.3080       12\n",
      "2.102387 1.960535        32768        32768.0   0.0000   3.2916       80\n",
      "1.975166 1.847945        65536        65536.0   4.0073   4.4924       50\n",
      "1.855999 1.736832       131072       131072.0   4.2341   2.0628       57\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 138330\n",
      "passes used = 1\n",
      "weighted example sum = 138330.000000\n",
      "weighted label sum = 387735.119964\n",
      "average loss = 1.848273\n",
      "best constant = 2.802972\n",
      "total feature number = 5409543\n",
      "Generating 2-grams for c namespaces.\n",
      "Generating 2-grams for t namespaces.\n",
      "final_regressor = ../../data/habr_popularity/model_1_2.vw\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = ../../data/habr_popularity/xaa\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.921812 1.921812            1            1.0   1.3863   0.0000      102\n",
      "1.902919 1.884025            2            2.0   1.3863   0.0137       56\n",
      "3.318742 4.734565            4            4.0   2.7081   0.1703       74\n",
      "3.499175 3.679609            8            8.0   0.6931   1.0398      121\n",
      "6.418531 9.337888           16           16.0   4.6913   0.2147        5\n",
      "7.531739 8.644947           32           32.0   0.0000   1.9904      120\n",
      "6.266162 5.000585           64           64.0   1.0986   0.7482        6\n",
      "5.826438 5.386715          128          128.0   4.9273   1.7163       81\n",
      "4.994882 4.163325          256          256.0   3.1781   2.7004       94\n",
      "4.298550 3.602218          512          512.0   4.9698   2.6680       71\n",
      "3.891336 3.484123         1024         1024.0   0.6931   1.6416       15\n",
      "3.481800 3.072264         2048         2048.0   4.9416   4.4972      153\n",
      "3.003601 2.525402         4096         4096.0   4.2627   2.5192        7\n",
      "2.671943 2.340285         8192         8192.0   3.7136   3.0752       47\n",
      "2.407018 2.142092        16384        16384.0   2.0794   2.1348       20\n",
      "2.207924 2.008831        32768        32768.0   0.0000   3.4559      156\n",
      "2.046599 1.885273        65536        65536.0   4.0073   4.6168       96\n",
      "1.906722 1.766844       131072       131072.0   4.2341   1.9563      109\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 138330\n",
      "passes used = 1\n",
      "weighted example sum = 138330.000000\n",
      "weighted label sum = 387735.119964\n",
      "average loss = 1.897651\n",
      "best constant = 2.802972\n",
      "total feature number = 10164007\n",
      "Generating 3-grams for c namespaces.\n",
      "Generating 3-grams for t namespaces.\n",
      "final_regressor = ../../data/habr_popularity/model_1_3.vw\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = ../../data/habr_popularity/xaa\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.921812 1.921812            1            1.0   1.3863   0.0000      150\n",
      "1.908886 1.895961            2            2.0   1.3863   0.0094       81\n",
      "3.392680 4.876474            4            4.0   2.7081   0.1250      108\n",
      "3.649840 3.907000            8            8.0   0.6931   0.7775      178\n",
      "7.167889 10.685937           16           16.0   4.6913   0.1659        5\n",
      "8.301461 9.435034           32           32.0   0.0000   1.5658      177\n",
      "6.848611 5.395761           64           64.0   1.0986   0.6124        6\n",
      "6.328596 5.808580          128          128.0   4.9273   1.5400      118\n",
      "5.338117 4.347638          256          256.0   3.1781   2.6551      138\n",
      "4.553058 3.767999          512          512.0   4.9698   2.6214      103\n",
      "4.143962 3.734866         1024         1024.0   0.6931   1.4341       19\n",
      "3.750474 3.356985         2048         2048.0   4.9416   4.4909      226\n",
      "3.279757 2.809040         4096         4096.0   4.2627   2.2811        7\n",
      "2.893028 2.506299         8192         8192.0   3.7136   2.9121       67\n",
      "2.568171 2.243313        16384        16384.0   2.0794   2.0022       27\n",
      "2.325584 2.082998        32768        32768.0   0.0000   3.3971      231\n",
      "2.131157 1.936730        65536        65536.0   4.0073   4.4456      141\n",
      "1.971441 1.811726       131072       131072.0   4.2341   1.8610      160\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 138330\n",
      "passes used = 1\n",
      "weighted example sum = 138330.000000\n",
      "weighted label sum = 387735.119964\n",
      "average loss = 1.961305\n",
      "best constant = 2.802972\n",
      "total feature number = 14780678\n",
      "final_regressor = ../../data/habr_popularity/model_3_1.vw\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "using cache_file = ../../data/habr_popularity/3_1_cache\n",
      "creating cache_file = ../../data/habr_popularity/xaa.cache\n",
      "ignoring text input in favor of cache input\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.921812 1.921812            1            1.0   1.3863   0.0000       53\n",
      "1.886483 1.851155            2            2.0   1.3863   0.0257       30\n",
      "3.139852 4.393220            4            4.0   2.7081   0.2815       39\n",
      "3.207326 3.274800            8            8.0   0.6931   1.5959       63\n",
      "5.804256 8.401185           16           16.0   3.9890   0.4546       12\n",
      "6.964433 8.124610           32           32.0   5.8636   1.4523       32\n",
      "5.798848 4.633263           64           64.0   4.9767   0.8026        5\n",
      "5.227036 4.655225          128          128.0   4.2195   2.7018       45\n",
      "4.577915 3.928793          256          256.0   0.6931   1.0882       13\n",
      "3.973515 3.369116          512          512.0   1.6094   1.4598        5\n",
      "3.564385 3.155255         1024         1024.0   4.3307   1.4285        4\n",
      "3.096096 2.627806         2048         2048.0   4.4308   3.0881       56\n",
      "2.656055 2.216014         4096         4096.0   3.8501   3.1585        9\n",
      "2.425368 2.194681         8192         8192.0   2.3979   1.8821       36\n",
      "2.260187 2.095007        16384        16384.0   2.8332   2.7641       46\n",
      "2.101884 1.943581        32768        32768.0   4.3307   2.6104       51\n",
      "1.976388 1.850893        65536        65536.0   4.5326   4.2265       22\n",
      "1.817725 1.817725       131072       131072.0   0.0000   0.9925       28 h\n",
      "1.733886 1.650053       262144       262144.0   2.3026   1.8103       27 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 124497\n",
      "passes used = 3\n",
      "weighted example sum = 373491.000000\n",
      "weighted label sum = 1045750.649264\n",
      "average loss = 1.638335 h\n",
      "best constant = 2.799935\n",
      "total feature number = 14617821\n",
      "Generating 2-grams for c namespaces.\n",
      "Generating 2-grams for t namespaces.\n",
      "final_regressor = ../../data/habr_popularity/model_3_2.vw\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "using cache_file = ../../data/habr_popularity/3_2_cache\n",
      "using cache_file = ../../data/habr_popularity/xaa.cache\n",
      "ignoring text input in favor of cache input\n",
      "num sources = 2\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.921812 1.921812            1            1.0   1.3863   0.0000      102\n",
      "1.902919 1.884025            2            2.0   1.3863   0.0137       56\n",
      "3.318742 4.734565            4            4.0   2.7081   0.1703       74\n",
      "3.499175 3.679609            8            8.0   0.6931   1.0398      121\n",
      "6.820184 10.141192           16           16.0   3.9890   0.3056       19\n",
      "8.021171 9.222159           32           32.0   5.8636   1.0432       59\n",
      "6.496122 4.971073           64           64.0   4.9767   0.5909        6\n",
      "5.846296 5.196471          128          128.0   4.2195   2.3418       86\n",
      "5.013123 4.179949          256          256.0   0.6931   0.9101       21\n",
      "4.367544 3.721965          512          512.0   1.6094   1.1091        5\n",
      "3.956147 3.544749         1024         1024.0   4.3307   1.1124        4\n",
      "3.476588 2.997030         2048         2048.0   4.4308   3.1637      107\n",
      "2.993243 2.509899         4096         4096.0   3.8501   3.0832       13\n",
      "2.654794 2.316345         8192         8192.0   2.3979   1.8994       67\n",
      "2.418567 2.182339        16384        16384.0   2.8332   2.9294       88\n",
      "2.202924 1.987282        32768        32768.0   4.3307   2.7312       97\n",
      "2.043841 1.884758        65536        65536.0   4.5326   3.9658       40\n",
      "1.862423 1.681004       131072       131072.0   0.0000   0.5798       51\n",
      "1.787040 1.787040       262144       262144.0   2.3026   2.1947       50 h\n",
      "1.734067 1.681094       524288       524288.0   3.8501   3.5863        9 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 248994\n",
      "passes used = 3\n",
      "weighted example sum = 746982.000000\n",
      "weighted label sum = 2091501.298527\n",
      "average loss = 1.681011 h\n",
      "best constant = 2.799935\n",
      "total feature number = 54933420\n",
      "Generating 3-grams for c namespaces.\n",
      "Generating 3-grams for t namespaces.\n",
      "final_regressor = ../../data/habr_popularity/model_3_3.vw\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "using cache_file = ../../data/habr_popularity/3_3_cache\n",
      "using cache_file = ../../data/habr_popularity/xaa.cache\n",
      "ignoring text input in favor of cache input\n",
      "num sources = 2\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.921812 1.921812            1            1.0   1.3863   0.0000      150\n",
      "1.908886 1.895961            2            2.0   1.3863   0.0094       81\n",
      "3.392680 4.876474            4            4.0   2.7081   0.1250      108\n",
      "3.649840 3.907000            8            8.0   0.6931   0.7775      178\n",
      "7.402185 11.154530           16           16.0   3.9890   0.2354       25\n",
      "8.666661 9.931138           32           32.0   5.8636   0.8201       85\n",
      "7.027052 5.387442           64           64.0   4.9767   0.4811        6\n",
      "6.376097 5.725143          128          128.0   4.2195   2.0273      126\n",
      "5.349529 4.322961          256          256.0   0.6931   0.8140       28\n",
      "4.617335 3.885142          512          512.0   1.6094   0.9416        5\n",
      "4.212620 3.807906         1024         1024.0   4.3307   0.9533        4\n",
      "3.748009 3.283397         2048         2048.0   4.4308   3.1433      157\n",
      "3.268526 2.789043         4096         4096.0   3.8501   2.9113       16\n",
      "2.870043 2.471560         8192         8192.0   2.3979   1.9434       97\n",
      "2.578435 2.286826        16384        16384.0   2.8332   2.7770      129\n",
      "2.318717 2.059000        32768        32768.0   4.3307   2.7613      142\n",
      "2.127184 1.935650        65536        65536.0   4.5326   3.6650       57\n",
      "1.923048 1.718913       131072       131072.0   0.0000   0.5217       73\n",
      "1.838047 1.838047       262144       262144.0   2.3026   2.1375       72 h\n",
      "1.777468 1.716889       524288       524288.0   3.8501   3.5495       10 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 248994\n",
      "passes used = 3\n",
      "weighted example sum = 746982.000000\n",
      "weighted label sum = 2091501.298527\n",
      "average loss = 1.713847 h\n",
      "best constant = 2.799935\n",
      "total feature number = 79887078\n",
      "final_regressor = ../../data/habr_popularity/model_5_1.vw\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "using cache_file = ../../data/habr_popularity/5_1_cache\n",
      "using cache_file = ../../data/habr_popularity/xaa.cache\n",
      "ignoring text input in favor of cache input\n",
      "num sources = 2\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.921812 1.921812            1            1.0   1.3863   0.0000       53\n",
      "1.886483 1.851155            2            2.0   1.3863   0.0257       30\n",
      "3.139852 4.393220            4            4.0   2.7081   0.2815       39\n",
      "3.207326 3.274800            8            8.0   0.6931   1.5959       63\n",
      "5.804256 8.401185           16           16.0   3.9890   0.4546       12\n",
      "6.964433 8.124610           32           32.0   5.8636   1.4523       32\n",
      "5.798848 4.633263           64           64.0   4.9767   0.8026        5\n",
      "5.227036 4.655225          128          128.0   4.2195   2.7018       45\n",
      "4.577915 3.928793          256          256.0   0.6931   1.0882       13\n",
      "3.973515 3.369116          512          512.0   1.6094   1.4598        5\n",
      "3.564385 3.155255         1024         1024.0   4.3307   1.4285        4\n",
      "3.096096 2.627806         2048         2048.0   4.4308   3.0881       56\n",
      "2.656055 2.216014         4096         4096.0   3.8501   3.1585        9\n",
      "2.425368 2.194681         8192         8192.0   2.3979   1.8821       36\n",
      "2.260187 2.095007        16384        16384.0   2.8332   2.7641       46\n",
      "2.101884 1.943581        32768        32768.0   4.3307   2.6104       51\n",
      "1.976388 1.850893        65536        65536.0   4.5326   4.2265       22\n",
      "1.829680 1.682973       131072       131072.0   0.0000   0.9925       28\n",
      "1.733886 1.733886       262144       262144.0   2.3026   1.8103       27 h\n",
      "1.687045 1.640203       524288       524288.0   3.8501   3.5331        7 h\n",
      "1.678189 1.669333      1048576      1048576.0   5.3799   6.0739      171 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 248994\n",
      "passes used = 5\n",
      "weighted example sum = 1244970.000000\n",
      "weighted label sum = 3485835.497545\n",
      "average loss = 1.638895 h\n",
      "best constant = 2.799935\n",
      "total feature number = 48726070\n",
      "Generating 2-grams for c namespaces.\n",
      "Generating 2-grams for t namespaces.\n",
      "final_regressor = ../../data/habr_popularity/model_5_2.vw\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "using cache_file = ../../data/habr_popularity/5_2_cache\n",
      "using cache_file = ../../data/habr_popularity/xaa.cache\n",
      "ignoring text input in favor of cache input\n",
      "num sources = 2\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.921812 1.921812            1            1.0   1.3863   0.0000      102\n",
      "1.902919 1.884025            2            2.0   1.3863   0.0137       56\n",
      "3.318742 4.734565            4            4.0   2.7081   0.1703       74\n",
      "3.499175 3.679609            8            8.0   0.6931   1.0398      121\n",
      "6.820184 10.141192           16           16.0   3.9890   0.3056       19\n",
      "8.021171 9.222159           32           32.0   5.8636   1.0432       59\n",
      "6.496122 4.971073           64           64.0   4.9767   0.5909        6\n",
      "5.846296 5.196471          128          128.0   4.2195   2.3418       86\n",
      "5.013123 4.179949          256          256.0   0.6931   0.9101       21\n",
      "4.367544 3.721965          512          512.0   1.6094   1.1091        5\n",
      "3.956147 3.544749         1024         1024.0   4.3307   1.1124        4\n",
      "3.476588 2.997030         2048         2048.0   4.4308   3.1637      107\n",
      "2.993243 2.509899         4096         4096.0   3.8501   3.0832       13\n",
      "2.654794 2.316345         8192         8192.0   2.3979   1.8994       67\n",
      "2.418567 2.182339        16384        16384.0   2.8332   2.9294       88\n",
      "2.202924 1.987282        32768        32768.0   4.3307   2.7312       97\n",
      "2.043841 1.884758        65536        65536.0   4.5326   3.9658       40\n",
      "1.862423 1.681004       131072       131072.0   0.0000   0.5798       51\n",
      "1.787040 1.787040       262144       262144.0   2.3026   2.1947       50 h\n",
      "1.734067 1.681094       524288       524288.0   3.8501   3.5863        9 h\n",
      "1.713737 1.693408      1048576      1048576.0   5.3799   5.4602      337 h\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "finished run\n",
      "number of examples per pass = 248994\n",
      "passes used = 5\n",
      "weighted example sum = 1244970.000000\n",
      "weighted label sum = 3485835.497545\n",
      "average loss = 1.681011 h\n",
      "best constant = 2.799935\n",
      "total feature number = 91555700\n",
      "Generating 3-grams for c namespaces.\n",
      "Generating 3-grams for t namespaces.\n",
      "final_regressor = ../../data/habr_popularity/model_5_3.vw\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "using cache_file = ../../data/habr_popularity/5_3_cache\n",
      "using cache_file = ../../data/habr_popularity/xaa.cache\n",
      "ignoring text input in favor of cache input\n",
      "num sources = 2\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.921812 1.921812            1            1.0   1.3863   0.0000      150\n",
      "1.908886 1.895961            2            2.0   1.3863   0.0094       81\n",
      "3.392680 4.876474            4            4.0   2.7081   0.1250      108\n",
      "3.649840 3.907000            8            8.0   0.6931   0.7775      178\n",
      "7.402185 11.154530           16           16.0   3.9890   0.2354       25\n",
      "8.666661 9.931138           32           32.0   5.8636   0.8201       85\n",
      "7.027052 5.387442           64           64.0   4.9767   0.4811        6\n",
      "6.376097 5.725143          128          128.0   4.2195   2.0273      126\n",
      "5.349529 4.322961          256          256.0   0.6931   0.8140       28\n",
      "4.617335 3.885142          512          512.0   1.6094   0.9416        5\n",
      "4.212620 3.807906         1024         1024.0   4.3307   0.9533        4\n",
      "3.748009 3.283397         2048         2048.0   4.4308   3.1433      157\n",
      "3.268526 2.789043         4096         4096.0   3.8501   2.9113       16\n",
      "2.870043 2.471560         8192         8192.0   2.3979   1.9434       97\n",
      "2.578435 2.286826        16384        16384.0   2.8332   2.7770      129\n",
      "2.318717 2.059000        32768        32768.0   4.3307   2.7613      142\n",
      "2.127184 1.935650        65536        65536.0   4.5326   3.6650       57\n",
      "1.923048 1.718913       131072       131072.0   0.0000   0.5217       73\n",
      "1.838047 1.838047       262144       262144.0   2.3026   2.1375       72 h\n",
      "1.777468 1.716889       524288       524288.0   3.8501   3.5495       10 h\n",
      "1.747616 1.717763      1048576      1048576.0   5.3799   5.4442      502 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 248994\n",
      "passes used = 5\n",
      "weighted example sum = 1244970.000000\n",
      "weighted label sum = 3485835.497545\n",
      "average loss = 1.713847 h\n",
      "best constant = 2.799935\n",
      "total feature number = 133145130\n",
      "CPU times: user 6.82 s, sys: 1 s, total: 7.82 s\n",
      "Wall time: 4min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "!vw --passes 1 -d ../../data/habr_popularity/xaa -b 28 -f ../../data/habr_popularity/model_1_1.vw\n",
    "!vw --passes 1 --ngram c2 --ngram t2 -d ../../data/habr_popularity/xaa -b 28 -f ../../data/habr_popularity/model_1_2.vw\n",
    "!vw --passes 1 --ngram c3 --ngram t3 -d ../../data/habr_popularity/xaa -b 28 -f ../../data/habr_popularity/model_1_3.vw\n",
    "\n",
    "!vw -c --cache_file ../../data/habr_popularity/3_1_cache --passes 3 -d ../../data/habr_popularity/xaa -b 28 -f ../../data/habr_popularity/model_3_1.vw\n",
    "!vw -c --cache_file ../../data/habr_popularity/3_2_cache --passes 3 --ngram c2 --ngram t2 -d ../../data/habr_popularity/xaa -b 28 -f ../../data/habr_popularity/model_3_2.vw\n",
    "!vw -c --cache_file ../../data/habr_popularity/3_3_cache --passes 3 --ngram c3 --ngram t3 -d ../../data/habr_popularity/xaa -b 28 -f ../../data/habr_popularity/model_3_3.vw\n",
    "\n",
    "!vw -c --cache_file ../../data/habr_popularity/5_1_cache --passes 5 -d ../../data/habr_popularity/xaa -b 28 -f ../../data/habr_popularity/model_5_1.vw\n",
    "!vw -c --cache_file ../../data/habr_popularity/5_2_cache --passes 5 --ngram c2 --ngram t2 -d ../../data/habr_popularity/xaa -b 28 -f ../../data/habr_popularity/model_5_2.vw\n",
    "!vw -c --cache_file ../../data/habr_popularity/5_3_cache --passes 5 --ngram c3 --ngram t3 -d ../../data/habr_popularity/xaa -b 28 -f ../../data/habr_popularity/model_5_3.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only testing\n",
      "predictions = ../../data/habr_popularity/model_1_1.predictions\n",
      "Num weight bits = 24\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = ../../data/habr_popularity/xab\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.344693 0.344693            1            1.0   2.5649   3.1521       50\n",
      "0.634031 0.923370            2            2.0   4.1744   3.2135       26\n",
      "0.465276 0.296520            4            4.0   1.3863   1.7583       18\n",
      "0.846801 1.228326            8            8.0   0.0000   0.7849       54\n",
      "0.877162 0.907524           16           16.0   2.5649   2.7634       19\n",
      "1.076894 1.276625           32           32.0   0.0000   0.0000       80\n",
      "1.592764 2.108635           64           64.0   1.7918   4.4855       69\n",
      "1.432847 1.272929          128          128.0   3.5553   3.1672       40\n",
      "1.622036 1.811225          256          256.0   1.0986   2.3208       53\n",
      "1.665786 1.709537          512          512.0   2.3026   0.9260       21\n",
      "1.629783 1.593780         1024         1024.0   0.6931   1.3869       46\n",
      "1.700480 1.771177         2048         2048.0   2.7081   0.8845       14\n",
      "1.685814 1.671148         4096         4096.0   0.0000   2.2185       37\n",
      "1.689809 1.693805         8192         8192.0   3.2581   3.2588        6\n",
      "1.692534 1.695259        16384        16384.0   3.5264   3.1706       23\n",
      "1.682671 1.672807        32768        32768.0   4.4886   3.9770        8\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 34583\n",
      "passes used = 1\n",
      "weighted example sum = 34583.000000\n",
      "weighted label sum = 96818.099835\n",
      "average loss = 1.680591\n",
      "best constant = 2.799587\n",
      "total feature number = 1353876\n",
      "Generating 2-grams for c namespaces.\n",
      "Generating 2-grams for t namespaces.\n",
      "only testing\n",
      "predictions = ../../data/habr_popularity/model_1_2.predictions\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = ../../data/habr_popularity/xab\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.038222 0.038222            1            1.0   2.5649   2.3694       96\n",
      "0.296830 0.555437            2            2.0   4.1744   3.4291       48\n",
      "0.228068 0.159307            4            4.0   1.3863   1.8164       32\n",
      "1.141250 2.054432            8            8.0   0.0000   1.0700      103\n",
      "1.024139 0.907028           16           16.0   2.5649   2.5605       34\n",
      "1.210660 1.397182           32           32.0   0.0000   0.0000      156\n",
      "1.611887 2.013113           64           64.0   1.7918   4.1338      134\n",
      "1.390676 1.169466          128          128.0   3.5553   3.1795       76\n",
      "1.686305 1.981934          256          256.0   1.0986   2.0904      101\n",
      "1.657381 1.628457          512          512.0   2.3026   1.4297       31\n",
      "1.665116 1.672850         1024         1024.0   0.6931   1.3772       88\n",
      "1.747586 1.830056         2048         2048.0   2.7081   1.1578       17\n",
      "1.726285 1.704983         4096         4096.0   0.0000   2.5141       70\n",
      "1.715765 1.705245         8192         8192.0   3.2581   3.6319        7\n",
      "1.719200 1.722636        16384        16384.0   3.5264   3.1475       41\n",
      "1.712000 1.704800        32768        32768.0   4.4886   3.6588       11\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 34583\n",
      "passes used = 1\n",
      "weighted example sum = 34583.000000\n",
      "weighted label sum = 96818.099835\n",
      "average loss = 1.712388\n",
      "best constant = 2.799587\n",
      "total feature number = 2543917\n",
      "Generating 3-grams for c namespaces.\n",
      "Generating 3-grams for t namespaces.\n",
      "only testing\n",
      "predictions = ../../data/habr_popularity/model_1_3.predictions\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = ../../data/habr_popularity/xab\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.039787 0.039787            1            1.0   2.5649   2.3655      141\n",
      "0.246196 0.452605            2            2.0   4.1744   3.5016       69\n",
      "0.281809 0.317423            4            4.0   1.3863   1.8830       45\n",
      "1.289161 2.296513            8            8.0   0.0000   1.3384      151\n",
      "1.128134 0.967106           16           16.0   2.5649   2.4827       48\n",
      "1.295367 1.462601           32           32.0   0.0000   0.0000      231\n",
      "1.724698 2.154029           64           64.0   1.7918   4.1934      198\n",
      "1.441017 1.157336          128          128.0   3.5553   3.1149      111\n",
      "1.755529 2.070041          256          256.0   1.0986   2.1848      148\n",
      "1.719347 1.683164          512          512.0   2.3026   1.4741       40\n",
      "1.727410 1.735473         1024         1024.0   0.6931   1.2437      129\n",
      "1.797449 1.867489         2048         2048.0   2.7081   1.1469       19\n",
      "1.776896 1.756342         4096         4096.0   0.0000   2.4571      102\n",
      "1.762484 1.748072         8192         8192.0   3.2581   3.6632        7\n",
      "1.762165 1.761847        16384        16384.0   3.5264   3.1425       58\n",
      "1.755753 1.749341        32768        32768.0   4.4886   3.6827       13\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 34583\n",
      "passes used = 1\n",
      "weighted example sum = 34583.000000\n",
      "weighted label sum = 96818.099835\n",
      "average loss = 1.756755\n",
      "best constant = 2.799587\n",
      "total feature number = 3699633\n",
      "only testing\n",
      "predictions = ../../data/habr_popularity/model_3_1.predictions\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = ../../data/habr_popularity/xab\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.407816 0.407816            1            1.0   2.5649   3.2036       50\n",
      "0.699856 0.991895            2            2.0   4.1744   3.1784       26\n",
      "0.515100 0.330345            4            4.0   1.3863   1.7771       18\n",
      "0.937843 1.360586            8            8.0   0.0000   1.0139       54\n",
      "0.907670 0.877497           16           16.0   2.5649   2.7744       19\n",
      "1.087004 1.266337           32           32.0   0.0000   0.0000       80\n",
      "1.562041 2.037079           64           64.0   1.7918   4.7610       69\n",
      "1.389398 1.216755          128          128.0   3.5553   3.0712       40\n",
      "1.597209 1.805021          256          256.0   1.0986   2.5253       53\n",
      "1.625999 1.654789          512          512.0   2.3026   1.0256       21\n",
      "1.601060 1.576121         1024         1024.0   0.6931   1.3627       46\n",
      "1.684144 1.767228         2048         2048.0   2.7081   1.0863       14\n",
      "1.668368 1.652592         4096         4096.0   0.0000   2.0624       37\n",
      "1.671724 1.675080         8192         8192.0   3.2581   3.2166        6\n",
      "1.675559 1.679394        16384        16384.0   3.5264   3.1713       23\n",
      "1.664142 1.652725        32768        32768.0   4.4886   3.9808        8\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 34583\n",
      "passes used = 1\n",
      "weighted example sum = 34583.000000\n",
      "weighted label sum = 96818.099835\n",
      "average loss = 1.662923\n",
      "best constant = 2.799587\n",
      "total feature number = 1353876\n",
      "Generating 2-grams for c namespaces.\n",
      "Generating 2-grams for t namespaces.\n",
      "only testing\n",
      "predictions = ../../data/habr_popularity/model_3_2.predictions\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = ../../data/habr_popularity/xab\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.119777 0.119777            1            1.0   2.5649   2.2189       96\n",
      "0.364538 0.609299            2            2.0   4.1744   3.3938       48\n",
      "0.286914 0.209289            4            4.0   1.3863   1.2206       32\n",
      "1.027998 1.769083            8            8.0   0.0000   0.9015      103\n",
      "0.986928 0.945858           16           16.0   2.5649   2.4323       34\n",
      "1.163704 1.340480           32           32.0   0.0000   0.0000      156\n",
      "1.598761 2.033818           64           64.0   1.7918   4.1732      134\n",
      "1.411023 1.223285          128          128.0   3.5553   3.1799       76\n",
      "1.641282 1.871542          256          256.0   1.0986   2.2365      101\n",
      "1.675135 1.708988          512          512.0   2.3026   1.3081       31\n",
      "1.648162 1.621189         1024         1024.0   0.6931   1.3318       88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.736068 1.823974         2048         2048.0   2.7081   1.1317       17\n",
      "1.713270 1.690472         4096         4096.0   0.0000   2.3496       70\n",
      "1.706093 1.698916         8192         8192.0   3.2581   3.5663        7\n",
      "1.714074 1.722054        16384        16384.0   3.5264   3.1302       41\n",
      "1.708363 1.702652        32768        32768.0   4.4886   4.0521       11\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 34583\n",
      "passes used = 1\n",
      "weighted example sum = 34583.000000\n",
      "weighted label sum = 96818.099835\n",
      "average loss = 1.707579\n",
      "best constant = 2.799587\n",
      "total feature number = 2543917\n",
      "Generating 3-grams for c namespaces.\n",
      "Generating 3-grams for t namespaces.\n",
      "only testing\n",
      "predictions = ../../data/habr_popularity/model_3_3.predictions\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = ../../data/habr_popularity/xab\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.050603 0.050603            1            1.0   2.5649   2.3400      141\n",
      "0.200695 0.350786            2            2.0   4.1744   3.5821       69\n",
      "0.216239 0.231782            4            4.0   1.3863   1.4686       45\n",
      "1.200542 2.184845            8            8.0   0.0000   1.3243      151\n",
      "1.080488 0.960435           16           16.0   2.5649   2.4815       48\n",
      "1.264871 1.449254           32           32.0   0.0000   0.0000      231\n",
      "1.680917 2.096963           64           64.0   1.7918   4.1652      198\n",
      "1.442201 1.203484          128          128.0   3.5553   3.0608      111\n",
      "1.722994 2.003788          256          256.0   1.0986   2.3130      148\n",
      "1.726655 1.730315          512          512.0   2.3026   1.4553       40\n",
      "1.707391 1.688128         1024         1024.0   0.6931   0.9950      129\n",
      "1.778377 1.849362         2048         2048.0   2.7081   1.1824       19\n",
      "1.747496 1.716616         4096         4096.0   0.0000   2.3925      102\n",
      "1.734576 1.721656         8192         8192.0   3.2581   3.6685        7\n",
      "1.736254 1.737933        16384        16384.0   3.5264   3.1300       58\n",
      "1.731534 1.726813        32768        32768.0   4.4886   3.9987       13\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 34583\n",
      "passes used = 1\n",
      "weighted example sum = 34583.000000\n",
      "weighted label sum = 96818.099835\n",
      "average loss = 1.732144\n",
      "best constant = 2.799587\n",
      "total feature number = 3699633\n",
      "only testing\n",
      "predictions = ../../data/habr_popularity/model_5_1.predictions\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = ../../data/habr_popularity/xab\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.467087 0.467087            1            1.0   2.5649   3.2484       50\n",
      "0.757002 1.046917            2            2.0   4.1744   3.1512       26\n",
      "0.567192 0.377382            4            4.0   1.3863   1.7569       18\n",
      "0.941604 1.316015            8            8.0   0.0000   0.9987       54\n",
      "0.944840 0.948076           16           16.0   2.5649   2.7319       19\n",
      "1.103009 1.261179           32           32.0   0.0000   0.0000       80\n",
      "1.570045 2.037080           64           64.0   1.7918   4.7560       69\n",
      "1.405574 1.241103          128          128.0   3.5553   3.0024       40\n",
      "1.594129 1.782684          256          256.0   1.0986   2.5875       53\n",
      "1.634248 1.674366          512          512.0   2.3026   0.9480       21\n",
      "1.605025 1.575802         1024         1024.0   0.6931   1.3839       46\n",
      "1.685837 1.766649         2048         2048.0   2.7081   1.0741       14\n",
      "1.672197 1.658558         4096         4096.0   0.0000   1.9918       37\n",
      "1.677791 1.683385         8192         8192.0   3.2581   3.1696        6\n",
      "1.682374 1.686956        16384        16384.0   3.5264   3.1839       23\n",
      "1.670699 1.659024        32768        32768.0   4.4886   4.0632        8\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 34583\n",
      "passes used = 1\n",
      "weighted example sum = 34583.000000\n",
      "weighted label sum = 96818.099835\n",
      "average loss = 1.669257\n",
      "best constant = 2.799587\n",
      "total feature number = 1353876\n",
      "Generating 2-grams for c namespaces.\n",
      "Generating 2-grams for t namespaces.\n",
      "only testing\n",
      "predictions = ../../data/habr_popularity/model_5_2.predictions\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = ../../data/habr_popularity/xab\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.104562 0.104562            1            1.0   2.5649   2.2416       96\n",
      "0.381794 0.659026            2            2.0   4.1744   3.3626       48\n",
      "0.278829 0.175864            4            4.0   1.3863   1.3460       32\n",
      "1.034936 1.791043            8            8.0   0.0000   0.9373      103\n",
      "0.969852 0.904768           16           16.0   2.5649   2.4688       34\n",
      "1.166054 1.362256           32           32.0   0.0000   0.0000      156\n",
      "1.588557 2.011061           64           64.0   1.7918   4.1607      134\n",
      "1.390331 1.192104          128          128.0   3.5553   3.1938       76\n",
      "1.635878 1.881426          256          256.0   1.0986   2.1843      101\n",
      "1.663610 1.691341          512          512.0   2.3026   1.3364       31\n",
      "1.642953 1.622297         1024         1024.0   0.6931   1.3700       88\n",
      "1.731432 1.819912         2048         2048.0   2.7081   1.1342       17\n",
      "1.708939 1.686445         4096         4096.0   0.0000   2.3992       70\n",
      "1.700674 1.692409         8192         8192.0   3.2581   3.5958        7\n",
      "1.707705 1.714736        16384        16384.0   3.5264   3.1299       41\n",
      "1.700692 1.693678        32768        32768.0   4.4886   3.9728       11\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 34583\n",
      "passes used = 1\n",
      "weighted example sum = 34583.000000\n",
      "weighted label sum = 96818.099835\n",
      "average loss = 1.700325\n",
      "best constant = 2.799587\n",
      "total feature number = 2543917\n",
      "Generating 3-grams for c namespaces.\n",
      "Generating 3-grams for t namespaces.\n",
      "only testing\n",
      "predictions = ../../data/habr_popularity/model_5_3.predictions\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = ../../data/habr_popularity/xab\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.052012 0.052012            1            1.0   2.5649   2.3369      141\n",
      "0.153928 0.255844            2            2.0   4.1744   3.6686       69\n",
      "0.185887 0.217846            4            4.0   1.3863   1.3832       45\n",
      "1.186905 2.187924            8            8.0   0.0000   1.3269      151\n",
      "1.119110 1.051314           16           16.0   2.5649   2.5163       48\n",
      "1.277421 1.435733           32           32.0   0.0000   0.0000      231\n",
      "1.689203 2.100984           64           64.0   1.7918   4.1686      198\n",
      "1.471729 1.254256          128          128.0   3.5553   3.0575      111\n",
      "1.739502 2.007276          256          256.0   1.0986   2.3361      148\n",
      "1.744896 1.750290          512          512.0   2.3026   1.4424       40\n",
      "1.715956 1.687016         1024         1024.0   0.6931   0.9254      129\n",
      "1.785104 1.854251         2048         2048.0   2.7081   1.1780       19\n",
      "1.753015 1.720927         4096         4096.0   0.0000   2.3932      102\n",
      "1.739488 1.725960         8192         8192.0   3.2581   3.6370        7\n",
      "1.741863 1.744239        16384        16384.0   3.5264   3.1294       58\n",
      "1.738251 1.734638        32768        32768.0   4.4886   4.0775       13\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 34583\n",
      "passes used = 1\n",
      "weighted example sum = 34583.000000\n",
      "weighted label sum = 96818.099835\n",
      "average loss = 1.738616\n",
      "best constant = 2.799587\n",
      "total feature number = 3699633\n",
      "CPU times: user 736 ms, sys: 176 ms, total: 912 ms\n",
      "Wall time: 22.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!vw -t -i ../../data/habr_popularity/model_1_1.vw -d ../../data/habr_popularity/xab -p ../../data/habr_popularity/model_1_1.predictions\n",
    "!vw -t -i ../../data/habr_popularity/model_1_2.vw -d ../../data/habr_popularity/xab -p ../../data/habr_popularity/model_1_2.predictions\n",
    "!vw -t -i ../../data/habr_popularity/model_1_3.vw -d ../../data/habr_popularity/xab -p ../../data/habr_popularity/model_1_3.predictions\n",
    "\n",
    "!vw -t -i ../../data/habr_popularity/model_3_1.vw -d ../../data/habr_popularity/xab -p ../../data/habr_popularity/model_3_1.predictions\n",
    "!vw -t -i ../../data/habr_popularity/model_3_2.vw -d ../../data/habr_popularity/xab -p ../../data/habr_popularity/model_3_2.predictions\n",
    "!vw -t -i ../../data/habr_popularity/model_3_3.vw -d ../../data/habr_popularity/xab -p ../../data/habr_popularity/model_3_3.predictions\n",
    "\n",
    "!vw -t -i ../../data/habr_popularity/model_5_1.vw -d ../../data/habr_popularity/xab -p ../../data/habr_popularity/model_5_1.predictions\n",
    "!vw -t -i ../../data/habr_popularity/model_5_2.vw -d ../../data/habr_popularity/xab -p ../../data/habr_popularity/model_5_2.predictions\n",
    "!vw -t -i ../../data/habr_popularity/model_5_3.vw -d ../../data/habr_popularity/xab -p ../../data/habr_popularity/model_5_3.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_1_1.predictions: 1.6805911058338114\n",
      "model_1_2.predictions: 1.7123877136306151\n",
      "model_1_3.predictions: 1.7567544967336086\n",
      "model_3_1.predictions: 1.6629233797387080\n",
      "model_3_2.predictions: 1.7075790863386933\n",
      "model_3_3.predictions: 1.7321443497222855\n",
      "model_5_1.predictions: 1.6692574091059014\n",
      "model_5_2.predictions: 1.7003249636364874\n",
      "model_5_3.predictions: 1.7386155290809329\n"
     ]
    }
   ],
   "source": [
    "valid_labels = np.loadtxt('../../data/habr_popularity/xab_labels')\n",
    "model_predictions = ['model_1_1.predictions', 'model_1_2.predictions', 'model_1_3.predictions', \\\n",
    "                     'model_3_1.predictions', 'model_3_2.predictions', 'model_3_3.predictions', \\\n",
    "                     'model_5_1.predictions', 'model_5_2.predictions', 'model_5_3.predictions']\n",
    "\n",
    "for model in model_predictions:\n",
    "    vw_pred = np.loadtxt('../../data/habr_popularity/' + model)[:,0]\n",
    "    print (model + ': ' + \"{:2.16f}\".format(mean_squared_error(valid_labels, vw_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vw_true_valid = np.loadtxt('../../data/habr_popularity/xab_labels')\n",
    "vw_valid_pred = np.loadtxt('../../data/habr_popularity/valid_1_1.predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6803230621826402"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(vw_true_valid, vw_valid_pred[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only testing\n",
      "predictions = ../../data/habr_popularity/test_1_1.predictions\n",
      "Num weight bits = 24\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = ../../data/habr_popularity/test.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0  unknown   2.7262       45\n",
      "0.000000 0.000000            2            2.0  unknown   5.0520       19\n",
      "0.000000 0.000000            4            4.0  unknown   2.9245       20\n",
      "0.000000 0.000000            8            8.0  unknown   3.6799      102\n",
      "0.000000 0.000000           16           16.0  unknown   2.6853       64\n",
      "0.000000 0.000000           32           32.0  unknown   3.1512       63\n",
      "0.000000 0.000000           64           64.0  unknown   5.8371       36\n",
      "0.000000 0.000000          128          128.0  unknown   4.5595      122\n",
      "0.000000 0.000000          256          256.0  unknown   3.1643       72\n",
      "0.000000 0.000000          512          512.0  unknown   3.1153       40\n",
      "0.000000 0.000000         1024         1024.0  unknown   3.0245       25\n",
      "0.000000 0.000000         2048         2048.0  unknown   3.6824       45\n",
      "0.000000 0.000000         4096         4096.0  unknown   3.6078       82\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 5405\n",
      "passes used = 1\n",
      "weighted example sum = 5405.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.000000\n",
      "total feature number = 241063\n"
     ]
    }
   ],
   "source": [
    "!vw -t --loss_function squared -i ../../data/habr_popularity/model_1_1.vw -d ../../data/habr_popularity/test.vw -p ../../data/habr_popularity/test_1_1.predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vw_pred = np.loadtxt('../../data/habr_popularity/test_1_1.predictions')[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5405,)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vw_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5405, 1)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission = pd.read_csv('sample_submission.csv', index_col='_id')\n",
    "sample_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_submission['favs_lognorm'] = vw_pred\n",
    "sample_submission.to_csv('baseline.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
